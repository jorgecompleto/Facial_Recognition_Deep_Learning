{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZrGpAwGWV2rnDpZuVp-yvTeV0ETGj4RM",
      "authorship_tag": "ABX9TyMO+dKqk+O+w/ImOzmQE7zB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgecompleto/Facial_Recognition_Deep_Learning/blob/main/Facial_Recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Mount Github to Google Colab"
      ],
      "metadata": {
        "id": "6VHiluKdgWtF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7qPg3vsotzN",
        "outputId": "15d413ea-1010-49ad-f62b-188bbca27123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.17.1\n"
          ]
        }
      ],
      "source": [
        "!git version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tem-P9FvC4g",
        "outputId": "99fddd3f-48fe-4de7-e43e-7f8ab24049c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "username = 'jorgecompleto'\n",
        "repo = 'Facial_Recognition_Deep_Learning'"
      ],
      "metadata": {
        "id": "Updj3hcsvDAM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ_gIG9ZvDGh",
        "outputId": "278fbe0a-10dd-4e9b-9b9b-c4e69315bf5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Facial_Recognition_Deep_Learning'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:   8% (1/12)   \rUnpacking objects:  16% (2/12)   \rUnpacking objects:  25% (3/12)   \rUnpacking objects:  33% (4/12)   \rUnpacking objects:  41% (5/12)   \rUnpacking objects:  50% (6/12)   \rUnpacking objects:  58% (7/12)   \rUnpacking objects:  66% (8/12)   \rUnpacking objects:  75% (9/12)   \rUnpacking objects:  83% (10/12)   \rUnpacking objects:  91% (11/12)   \rUnpacking objects: 100% (12/12)   \rUnpacking objects: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygq1bj2xvwMF",
        "outputId": "a669ca3e-2418-44f9-c97d-e061af504787"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Facial_Recognition_Deep_Learning'\n",
            "/content/Facial_Recognition_Deep_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import libraries"
      ],
      "metadata": {
        "id": "UExR-7qdhqel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "lmxd6ugtvTwa"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Deep Learning - Project/data/'\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqiXQ4wdvUWN",
        "outputId": "112a7bf9-063a-4949-c67b-7f69db5bbda8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example_submission.csv',\n",
              " 'icml_face_data.csv',\n",
              " 'test.csv',\n",
              " 'train.csv',\n",
              " '.DS_Store',\n",
              " 'fer2013']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Read the csv containing the images and preprocess them"
      ],
      "metadata": {
        "id": "SJGmUTLjlAZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path + 'icml_face_data.csv')"
      ],
      "metadata": {
        "id": "WJ1mEjH3vUit"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s6xLNEiq1X4v",
        "outputId": "91c4b003-b690-4e57-fb94-76f3eedfbb88"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion     Usage                                             pixels\n",
              "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45a8ebd2-2eb0-419e-ac3e-eb8a772c7a81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Training</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Training</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Training</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Training</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45a8ebd2-2eb0-419e-ac3e-eb8a772c7a81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45a8ebd2-2eb0-419e-ac3e-eb8a772c7a81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45a8ebd2-2eb0-419e-ac3e-eb8a772c7a81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[' Usage'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYjsF9Mk7Ct7",
        "outputId": "d31705b3-ce1b-4d10-b7e6-f99647add772"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name:  Usage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = data[data[' Usage']=='Training']\n",
        "validation = data[data[' Usage']=='PublicTest']\n",
        "test = data[data[' Usage']=='PrivateTest']"
      ],
      "metadata": {
        "id": "fbgVZ_bx8Phn"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [train, validation, test]:\n",
        "    print(len(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGrfjZKs8YNO",
        "outputId": "756003df-80d0-4088-ba42-3d403f0dea82"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28709\n",
            "3589\n",
            "3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "ti5kIi7rOpSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "\n",
        "def prepare_data(df, data= None):\n",
        "    \"\"\" Prepare data for modeling \n",
        "        input: data frame with labels und pixel data\n",
        "        output: image and label array \"\"\"\n",
        "\n",
        "    image_array = np.zeros(shape=(len(df), 48, 48))\n",
        "    image_label = np.array(list(map(int, df['emotion'])))\n",
        "    \n",
        "    for i, row in enumerate(df.index):\n",
        "        image = np.fromstring(df.loc[row, ' pixels'], dtype= int, sep= ' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image_array[i] = image\n",
        "        \n",
        "    return image_array, image_label\n",
        "\n",
        "\n",
        "def plot_compare_distributions(array1, array2, title1='', title2=''):\n",
        "    ''' Builds 2 plots to compare label distribution in both train and validation\n",
        "    '''\n",
        "    df_array1 = pd.DataFrame()\n",
        "    df_array2 = pd.DataFrame()\n",
        "    df_array1['emotion'] = array1.argmax(axis=1)\n",
        "    df_array2['emotion'] = array2.argmax(axis=1)\n",
        "    \n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey= False)\n",
        "    x = emotions.values()\n",
        "    \n",
        "    y = df_array1['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[0].bar(x, y.sort_index(), color='orange')\n",
        "    axs[0].set_title(title1)\n",
        "    axs[0].grid()\n",
        "    \n",
        "    y = df_array2['emotion'].value_counts()\n",
        "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
        "    for key_missed in keys_missed:\n",
        "        y[key_missed] = 0\n",
        "    axs[1].bar(x, y.sort_index())\n",
        "    axs[1].set_title(title2)\n",
        "    axs[1].grid()\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MEIarLOx1byS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Transform the data from the csv to an array of pixels"
      ],
      "metadata": {
        "id": "QpQzCL21oSV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_array, train_image_label = prepare_data(train)\n",
        "val_image_array, val_image_label = prepare_data(validation)\n",
        "test_image_array, test_image_label = prepare_data(test)"
      ],
      "metadata": {
        "id": "fK-emxRNHL4w"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Reshape the array to fit the model"
      ],
      "metadata": {
        "id": "RuR-5Q2qobPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_image_array.reshape((len(train_image_array), 48, 48, 1))\n",
        "val_images = val_image_array.reshape((len(val_image_array), 48, 48, 1))\n",
        "test_images = test_image_array.reshape((len(test_image_array), 48, 48, 1))\n",
        "# reshape to the lenght of the array, the width and height of each image, and 1 because all images are grey scale so no RGB included\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "val_images = val_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "# rescale the array, CNNs prefer values comprehended from 0 to 1"
      ],
      "metadata": {
        "id": "f3fP3wCGKXxE"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Encode labels"
      ],
      "metadata": {
        "id": "MwRi3gs33xDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(train_image_label)\n",
        "val_labels = to_categorical(val_image_label)\n",
        "test_labels = to_categorical(test_image_label)"
      ],
      "metadata": {
        "id": "DcK6N4am2pK3"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Instantiate a small CNN"
      ],
      "metadata": {
        "id": "u-nJKTS2_o9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Convolutional base"
      ],
      "metadata": {
        "id": "87nk_mPuCA6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation= 'relu', input_shape= (48, 48, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation= 'relu'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9itQpyms5c2Q",
        "outputId": "ed06e6a0-6267-4e3d-c09f-fbf848f986a9"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 23, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Dense base"
      ],
      "metadata": {
        "id": "WpEHvuv3E51O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation= 'relu'))\n",
        "model.add(layers.Dense(7, activation= 'softmax'))"
      ],
      "metadata": {
        "id": "02S6zbeXB7Bz"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRau-NnsFu-e",
        "outputId": "9a1b4c4e-d428-4d78-9e08-b1d483e7a75b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 23, 23, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 21, 21, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                262208    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 318,407\n",
            "Trainable params: 318,407\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Model Fit"
      ],
      "metadata": {
        "id": "oM0z89baF7qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= Adam(lr= 0.0001, decay= 1e-6), \n",
        "              loss= 'categorical_crossentropy', \n",
        "              metrics= ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs= 50, batch_size= 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNv_YU02F-aZ",
        "outputId": "b1236808-88b1-47bc-d801-d1ad3c312fc3"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "449/449 [==============================] - 4s 7ms/step - loss: 1.7831 - accuracy: 0.2698\n",
            "Epoch 2/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.6295 - accuracy: 0.3704\n",
            "Epoch 3/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.5695 - accuracy: 0.4001\n",
            "Epoch 4/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.5224 - accuracy: 0.4178\n",
            "Epoch 5/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.4825 - accuracy: 0.4345\n",
            "Epoch 6/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.4445 - accuracy: 0.4508\n",
            "Epoch 7/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.4138 - accuracy: 0.4630\n",
            "Epoch 8/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.3819 - accuracy: 0.4753\n",
            "Epoch 9/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.3552 - accuracy: 0.4872\n",
            "Epoch 10/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.3338 - accuracy: 0.4922\n",
            "Epoch 11/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.3112 - accuracy: 0.5010\n",
            "Epoch 12/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2924 - accuracy: 0.5118\n",
            "Epoch 13/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2736 - accuracy: 0.5192\n",
            "Epoch 14/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2569 - accuracy: 0.5270\n",
            "Epoch 15/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2403 - accuracy: 0.5325\n",
            "Epoch 16/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2223 - accuracy: 0.5401\n",
            "Epoch 17/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.2073 - accuracy: 0.5479\n",
            "Epoch 18/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1904 - accuracy: 0.5566\n",
            "Epoch 19/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1749 - accuracy: 0.5599\n",
            "Epoch 20/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1592 - accuracy: 0.5689\n",
            "Epoch 21/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1438 - accuracy: 0.5739\n",
            "Epoch 22/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1327 - accuracy: 0.5793\n",
            "Epoch 23/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1159 - accuracy: 0.5880\n",
            "Epoch 24/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.1033 - accuracy: 0.5923\n",
            "Epoch 25/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0885 - accuracy: 0.5972\n",
            "Epoch 26/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0747 - accuracy: 0.6043\n",
            "Epoch 27/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0612 - accuracy: 0.6088\n",
            "Epoch 28/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0483 - accuracy: 0.6137\n",
            "Epoch 29/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0338 - accuracy: 0.6233\n",
            "Epoch 30/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0218 - accuracy: 0.6238\n",
            "Epoch 31/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 1.0101 - accuracy: 0.6277\n",
            "Epoch 32/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9938 - accuracy: 0.6368\n",
            "Epoch 33/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9826 - accuracy: 0.6404\n",
            "Epoch 34/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9679 - accuracy: 0.6474\n",
            "Epoch 35/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9563 - accuracy: 0.6499\n",
            "Epoch 36/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9419 - accuracy: 0.6578\n",
            "Epoch 37/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9289 - accuracy: 0.6619\n",
            "Epoch 38/50\n",
            "449/449 [==============================] - 4s 10ms/step - loss: 0.9175 - accuracy: 0.6672\n",
            "Epoch 39/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.9013 - accuracy: 0.6729\n",
            "Epoch 40/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8901 - accuracy: 0.6765\n",
            "Epoch 41/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8749 - accuracy: 0.6837\n",
            "Epoch 42/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8625 - accuracy: 0.6881\n",
            "Epoch 43/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8502 - accuracy: 0.6933\n",
            "Epoch 44/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8375 - accuracy: 0.7002\n",
            "Epoch 45/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8205 - accuracy: 0.7065\n",
            "Epoch 46/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.8099 - accuracy: 0.7094\n",
            "Epoch 47/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.7957 - accuracy: 0.7145\n",
            "Epoch 48/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.7836 - accuracy: 0.7201\n",
            "Epoch 49/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.7675 - accuracy: 0.7281\n",
            "Epoch 50/50\n",
            "449/449 [==============================] - 3s 7ms/step - loss: 0.7568 - accuracy: 0.7313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe1e2778b20>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(val_images, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siCk38fYHH6Q",
        "outputId": "f7cfef77-f876-4e03-e178-a37042bef126"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 1s 4ms/step - loss: 1.7029 - accuracy: 0.5344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_acc, test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohFyfaYuLFNz",
        "outputId": "75935022-6c8d-44e6-8388-c5cbed1ed7eb"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5344107151031494 1.7029157876968384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.0 Data Exploration"
      ],
      "metadata": {
        "id": "3FBpPqvXP1Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_compare_distributions(train_labels, val_labels, title1= 'Train Labels', title2= 'Validation Labels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "4q3KseYMLgsf",
        "outputId": "6eb1dc0b-f81a-4397-d003-2c51e9c2b898"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXUFD9UuQPzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}