{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZrGpAwGWV2rnDpZuVp-yvTeV0ETGj4RM",
      "authorship_tag": "ABX9TyNY6a2a8XhHmIc47+kXRyX0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgecompleto/Facial_Recognition_Deep_Learning/blob/main/Facial_Recognition_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Mount Github to Google Colab"
      ],
      "metadata": {
        "id": "6VHiluKdgWtF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7qPg3vsotzN",
        "outputId": "15d413ea-1010-49ad-f62b-188bbca27123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git version 2.17.1\n"
          ]
        }
      ],
      "source": [
        "!git version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tem-P9FvC4g",
        "outputId": "99fddd3f-48fe-4de7-e43e-7f8ab24049c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "username = 'jorgecompleto'\n",
        "repo = 'Facial_Recognition_Deep_Learning'"
      ],
      "metadata": {
        "id": "Updj3hcsvDAM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ_gIG9ZvDGh",
        "outputId": "278fbe0a-10dd-4e9b-9b9b-c4e69315bf5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Facial_Recognition_Deep_Learning'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)\u001b[K\rremote: Compressing objects:  18% (2/11)\u001b[K\rremote: Compressing objects:  27% (3/11)\u001b[K\rremote: Compressing objects:  36% (4/11)\u001b[K\rremote: Compressing objects:  45% (5/11)\u001b[K\rremote: Compressing objects:  54% (6/11)\u001b[K\rremote: Compressing objects:  63% (7/11)\u001b[K\rremote: Compressing objects:  72% (8/11)\u001b[K\rremote: Compressing objects:  81% (9/11)\u001b[K\rremote: Compressing objects:  90% (10/11)\u001b[K\rremote: Compressing objects: 100% (11/11)\u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:   8% (1/12)   \rUnpacking objects:  16% (2/12)   \rUnpacking objects:  25% (3/12)   \rUnpacking objects:  33% (4/12)   \rUnpacking objects:  41% (5/12)   \rUnpacking objects:  50% (6/12)   \rUnpacking objects:  58% (7/12)   \rUnpacking objects:  66% (8/12)   \rUnpacking objects:  75% (9/12)   \rUnpacking objects:  83% (10/12)   \rUnpacking objects:  91% (11/12)   \rUnpacking objects: 100% (12/12)   \rUnpacking objects: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygq1bj2xvwMF",
        "outputId": "e228ab98-2d3d-4874-a696-56f00e927750"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Facial_Recognition_Deep_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC8dKJOlxfhC",
        "outputId": "70fe16fe-7f67-434c-f190-908ac4b89976"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mtrain.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import libraries"
      ],
      "metadata": {
        "id": "UExR-7qdhqel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "lmxd6ugtvTwa"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Deep Learning - Project/data/'\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqiXQ4wdvUWN",
        "outputId": "112a7bf9-063a-4949-c67b-7f69db5bbda8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example_submission.csv',\n",
              " 'icml_face_data.csv',\n",
              " 'test.csv',\n",
              " 'train.csv',\n",
              " '.DS_Store',\n",
              " 'fer2013']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Read the images and preprocess them"
      ],
      "metadata": {
        "id": "SJGmUTLjlAZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')"
      ],
      "metadata": {
        "id": "WJ1mEjH3vUit"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s6xLNEiq1X4v",
        "outputId": "59fde8d3-7f7e-4edb-b675-5a596dcd5e32"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   emotion                                             pixels\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-352a406e-7c32-489d-9009-9c9cd56c87f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-352a406e-7c32-489d-9009-9c9cd56c87f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-352a406e-7c32-489d-9009-9c9cd56c87f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-352a406e-7c32-489d-9009-9c9cd56c87f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    \"\"\" Prepare data for modeling \n",
        "        input: data frame with labels und pixel data\n",
        "        output: image and label array \"\"\"\n",
        "    if str(data) == 'train':\n",
        "        image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "        image_label = np.array(list(map(int, data['emotion'])))\n",
        "    else:\n",
        "        image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "        image_label = 0\n",
        "    \n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, 'pixels'], dtype= int, sep= ' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image_array[i] = image\n",
        "        \n",
        "    return image_array, image_label"
      ],
      "metadata": {
        "id": "MEIarLOx1byS"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Transform the data from the csv to an array of pixels"
      ],
      "metadata": {
        "id": "QpQzCL21oSV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_array, train_image_label = prepare_data(train)\n",
        "test_image_array, test_image_label = prepare_data(test)\n",
        "del test_image_label"
      ],
      "metadata": {
        "id": "fK-emxRNHL4w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Reshape the array to fit the model"
      ],
      "metadata": {
        "id": "RuR-5Q2qobPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_image_array.reshape((len(train_image_array), 48, 48, 1))\n",
        "test_images = test_image_array.reshape((len(test_image_array), 48, 48, 1))\n",
        "# reshape to the lenght of the array, the width and height of each image, and 1 because all images are grey scale so no RGB included\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "# rescale the array, CNNs prefer values comprehended from 0 to 1"
      ],
      "metadata": {
        "id": "f3fP3wCGKXxE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU-P7WlBpVxB",
        "outputId": "6f3b7065-5f55-4a18-ec65-97468f2e5649"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mtrain.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    }
  ]
}